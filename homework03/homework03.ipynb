{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbdcU_Y93IXk"
      },
      "source": [
        "# Introduction to Artificial Intelligence - Homework Assignment 03 (20pts.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4y3pNY8D9VA"
      },
      "source": [
        "* NETIDs:\n",
        "\n",
        "This assignment covers the following topics:\n",
        "\n",
        "* Principle Component Analysis\n",
        "* KMeans Clustering\n",
        "* Support Vector Machines\n",
        "\n",
        "It will consist of 6 tasks:\n",
        "\n",
        "* Task 00: Load Dataset                                            (0 pts.)\n",
        "* Task 01: PCA Implementation                                      (3 pts.)\n",
        "* Task 02: Kmeans Clustering Implementation                        (4 pts.)\n",
        "* Task 03: Clustering Method Evaluation\n",
        "    * Task 03-1: IoU Metric Function Definition                    (1 pt. )\n",
        "    * Task 03-2: Clustering Method Evaluations                     (1 pt. )\n",
        "    * Task 03-3: Clustering Short Answer Questions                 (2 pts.)\n",
        "* Task 04: Supervised Image Segmentation\n",
        "    * Task 04-1: Feature vectors creation for SVM                  (3 pts.)\n",
        "    * Task 04-2: Support Vector Machine Function Definition        (1 pt. )\n",
        "    * Task 04-3: Properly set colab env                            (1 pt. ) \n",
        "    * Task 04-4: SVM Evaluation                                    (2 pts.)\n",
        "    * Task 04-5: SVM Short Answer Questions                        (2 pts.)\n",
        "* Task 05: Final Letter Data Extraction\n",
        "    * Task 05-1: Computer Vision Region Cropping Function          (0 pts.)\n",
        "    * Task 05-2: Letter Extraction                                 (0 pts.)\n",
        "\n",
        "Please complete all sections. Some questions may require written answers, while others may involve coding. Be sure to run your code cells to verify your solutions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnoT8sIj5n-i"
      },
      "source": [
        "### *Story Progression*\n",
        "\n",
        "The police need some help with those letters Detective Caulfield delivered during class. The letters appear to be newspaper cutouts all combined together into a single letter. The Police don't want to do all the manual work of converting the letters into a text format and so they've asked your your help!\n",
        "\n",
        "As you try to fight off the fall break hangover, you realize you can treat this as an image segmentation task. We need to figure out where in the entire image each letter is. After hairing the dog, you have another breakthrough idea, what if you just perform a clustering task with only two clusters, foreground and background?\n",
        "\n",
        "But the only way you can do clustering at all is if you load in those images and image masks.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/nd-cse-30124-fa25/nd-cse-30124-fa25.github.io/refs/heads/main/static/img/hw03/note_page_1.png\" alt=\"Map\" style=\"width: 49%; max-width: 800px; height: auto;\">\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/nd-cse-30124-fa25/nd-cse-30124-fa25.github.io/refs/heads/main/static/img/hw03/mask_page_1.png\" alt=\"Map\" style=\"width: 49%; max-width: 800px; height: auto;\">\n",
        "\n",
        "A mask is a binary image that shows where in the color image our \"objects\" of interest are. For this task, what we are worried about is the location of each letter. In order to measure how well our image segmentation methods perform, we can compare our segmented image to the mask to see how well we segmented each \"object\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgIkSlsd57ka"
      },
      "source": [
        "## Task 00: Load Data\n",
        "### Task 00: Description (0 pts.)\n",
        "#### Load image data using opencv\n",
        "\n",
        "For this task, we need to load in the images and corresponding image masks\n",
        "\n",
        "**[Note]:** We can use the imread function from the cv2 library to read our images in. We should end up with the actual images shape being (595, 420, 3) and the mask shape being (595, 420).\n",
        "\n",
        "Images are read in as an array with the format (H, W, C) with the final item being our colors (R, G, B). Since our masks are binary (black and white) we don't need that extra color channel as we can just store 0s or 1s for each of those.\n",
        "\n",
        "### Task 00: Code (0 pts.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn1cHKn_YV7X",
        "outputId": "24ca1e74-15d9-4431-e29d-2f134a0ba0f5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)  # all RuntimeWarnings\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set random seed for NumPyâ€™s random number generator\n",
        "#     Conceptually: makes random operations (e.g., random initialization in KMeans, shuffling data, or selecting random samples) produce the same results every time the code is run\n",
        "#     aka your code becomes reporducable\n",
        "np.random.seed(42)\n",
        "\n",
        "# If running on colab and you don't already have the necessary HW data, reclone it\n",
        "REPO_URL = \"https://github.com/nd-cse-30124-fa25/cse-30124-homeworks.git\"\n",
        "REPO_NAME = \"cse-30124-homeworks\"\n",
        "HW_FOLDER = \"homework03\"\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "\n",
        "    # Clone repo if not already present\n",
        "    if not os.path.exists(REPO_NAME):\n",
        "        !git clone {REPO_URL}\n",
        "\n",
        "    # cd into the homework folder\n",
        "    %cd {REPO_NAME}/{HW_FOLDER}\n",
        "\n",
        "    !git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "    !python rapidsai-csp-utils/colab/pip-install.py\n",
        "\n",
        "except ImportError:\n",
        "    print('Assignment does not appear to be running on colab, not cloning data repo nor installing CUML')\n",
        "    print('\\t[WARNING]: This means that your SVM will run very, very slowly')\n",
        "    print('\\t[WARNING]: It took me about 25 minutes to run it on my mac mini')\n",
        "    print('\\t[WARNING]: You could install CuML manually')\n",
        "\n",
        "# Load letters (modify these according to your actual data paths if needed)\n",
        "image_paths = [f'pages/note_page_{i}.png' for i in range(1, 5)]\n",
        "mask_paths = [f'pages/mask_page_{i}.png' for i in range(1, 5)]\n",
        "\n",
        "images = [cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB) for image_path in image_paths]\n",
        "masks = [cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) for mask_path in mask_paths]\n",
        "\n",
        "print('Image Dimensions:', images[0].shape)\n",
        "print('Mask Dimensions:', masks[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKlAiaM65DPH"
      },
      "source": [
        "### *Story Progression*\n",
        "\n",
        "You remember there were a couple of clustering methods in class, but you also remember that typically k-means clustering was the one used as a sort of litmus test, so you figure that may as well be the place to start. Due to the images being so large, if you tried to run agglomerative hierarchical clustering on them you'd crash your kernel 100% of the time (I did this last year)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgQOC7omrxAX"
      },
      "source": [
        "## Task 01: PCA Implementation (3 pts.)\n",
        "### Task 01: Description (0 pts.)\n",
        "#### PCA from scratch\n",
        "\n",
        "**[NOTE:]** To all three of you that are starting this over fall break, you don't need to actually write this PCA code in order to test everything else. All of the results given below with EV/explained variance set to `0.99/1.0` are essentially equivalent to running the method without PCA. You'll have to comment stuff out but you should be able to test your kmeans and svms just fine without it.\n",
        "\n",
        "The images are quite large: (595, 420, 3). If you considered every pixel in an image to be a data point, each of our 4 pages has: 595 x 420 x 3 = 749700 \"samples\" in it! If we can get away with not using all of them we probably should. Towards this end, you will need to implement PCA, which will allow you to reduce the dimensionality of the images while hopefully not losing too much fidelity.\n",
        "\n",
        "### Task 01: Code (3 pts.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fM6qB0rOaKt2"
      },
      "outputs": [],
      "source": [
        "class PCA:\n",
        "    def __init__(self, n_components=1.0):\n",
        "        \"\"\"\n",
        "        Basic PCA class\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_components:\n",
        "          - float in (0, 1] -> keep the minimum # of components to reach this\n",
        "                               fraction of explained variance\n",
        "        \"\"\"\n",
        "        self._expl_var = n_components\n",
        "\n",
        "    def fit(self, X):\n",
        "        \"\"\"\n",
        "        Fits class to input data\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "\n",
        "        X : array-like, shape (n_samples, n_features)\n",
        "            Data matrix.\n",
        "        \"\"\"\n",
        "\n",
        "        X = np.asarray(X, dtype=float)\n",
        "        n_samples, _ = X.shape\n",
        "\n",
        "        # TODO: Center the data\n",
        "\n",
        "        # TODO: Use Singular Value Decomposition to get the Singular Values and Explained Variance\n",
        "        # Hint: numpy has a built in function for calculating SVD\n",
        "        \n",
        "        # TODO: Decide how many components to keep based on n_components\n",
        "        \n",
        "        # Retain only the resolved number of components and related statistics\n",
        "        self.components_ = Vt[:self._n_components]\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Projects the input data into the space defined by the principal components\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like, shape (n_samples, n_features)\n",
        "            Data matrix.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Z : array-like, shape (n_samples, self._n_components)\n",
        "            Data matrix.\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO: Transform the dataset into the new space described by the principal components\n",
        "\n",
        "        return Z\n",
        "\n",
        "    def fit_transform(self, X):\n",
        "        return self.fit(X).transform(X)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 02: kmeans Implementation (4 pts.)\n",
        "### Task 02: Description (0 pts.)\n",
        "#### kmeans from scratch\n",
        "\n",
        "One of the most basic clustering methods is kmeans clustering, and it's often used as a first-pass/litmus test when clustering is needed. In the code block below, you're will implement the kmeans algorithm!\n",
        "\n",
        "Remember that there are 5 steps in kmeans clustering:\n",
        "\n",
        "1. Specify the number of clusters (centroids)\n",
        "2. Randomly select k samples from our data to start as the centroids of our k clusters\n",
        "3. Assign all unchosen samples to the closest cluster based on their euclidian distances to each of the centroids\n",
        "4. After assigning all samples, recalculate the centroid of each cluster by taking the average position of each sample in the cluster\n",
        "5. If the new centroids are close to the old ones the solution is stable, and we can stop, otherwise **[repeat steps 3 and 4 with the new centroids]**\n",
        "\n",
        "Due to the rather uncertain nature of what \"stable\" actually means, we're going to add two arguments to our kmeans: `max_iters` and `tol`. We will use `tol` as the threshold distance for centroid movement and if that is never triggered, we will end after `max_iters` (You shouldn't need to change the defaults I've set for these).\n",
        "\n",
        "### Task 02: Code (4 pts.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REdNDzKTc9Qd"
      },
      "outputs": [],
      "source": [
        "class kmeans():\n",
        "    def __init__(self, n_clusters, max_iters=300, tol=1e-4, random_state=None):\n",
        "        \"\"\"\n",
        "        Basic k-means clustering class\n",
        "\n",
        "        Parameters\n",
        "        ---------\n",
        "        n_clusters : int\n",
        "            Number of clusters.\n",
        "        max_iters : int\n",
        "            Maximum iterations per run.\n",
        "        tol : float\n",
        "            Convergence tolerance on centroid movement (L2 norm).\n",
        "        random_state : int or None\n",
        "            Seed for reproducibility.\n",
        "        \"\"\"\n",
        "\n",
        "        self._n_clusters = n_clusters\n",
        "        self._max_iters = max_iters\n",
        "        self._tol = tol\n",
        "        self._random_state = random_state\n",
        "\n",
        "    def _init_centroids(self, X):\n",
        "        \"\"\"\n",
        "        Randomly initializes centroids\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "\n",
        "        X : array-like, shape (n_samples, n_features)\n",
        "            Data matrix.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        X[idx].copy : ndarray, shape (n_clusters,)\n",
        "            Randomly selected centroids\n",
        "        \"\"\"\n",
        "\n",
        "        rng = np.random.default_rng(self._random_state)\n",
        "        n_samples, _ = X.shape\n",
        "\n",
        "        # TODO: Randomly select n_clusters centroids\n",
        "\n",
        "        return X[idx].copy()\n",
        "\n",
        "    def fit_predict(self, X):\n",
        "        \"\"\"\n",
        "        Basic k-means clustering.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like, shape (n_samples, n_features)\n",
        "            Data matrix.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.logical_not(labels.astype(bool)) : ndarray, shape (n_samples,)\n",
        "            Cluster assignment for each sample\n",
        "        \"\"\"\n",
        "        X = np.asarray(X, dtype=float)\n",
        "\n",
        "        labels = None\n",
        "        centroids = None\n",
        "\n",
        "        # TODO: Initialize centroids\n",
        "\n",
        "        for _ in range(self._max_iters):\n",
        "            # TODO: Calculate euclidian distances for each point from the centroids\n",
        "            # TODO: Assign each sample to the closest centroid\n",
        "\n",
        "            # TODO: For each cluster that has members, calculate the average position of members\n",
        "            # TODO: For each cluster that doesn't have members, reseed it to the furthest point\n",
        "            # TODO: Replace the original Centroids with these new average positions\n",
        "\n",
        "            # TODO: Calculate the centroid movement and compare to tol\n",
        "\n",
        "            if shift < self._tol:\n",
        "                break\n",
        "\n",
        "        # Flip the foreground and background labels to match the sklearn output\n",
        "        return np.logical_not(labels.astype(bool))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGg8_Hn07HRE"
      },
      "source": [
        "## Task 3: Evaluating Unsupervised Segmentation (4 pts.)\n",
        "### Task 03-1: Description (0 pts.)\n",
        "#### Intersection over Union\n",
        "\n",
        "We'll need to evaluate how well our segmentation methods are doing. We can use the intersection over union (IoU) metric to evaluate how well our segmentation methods are doing.\n",
        "\n",
        "Intersection over Union (IoU) is defined as the intersection of the predicted mask and the ground truth mask divided by the union of the predicted mask and the ground truth mask.\n",
        "\n",
        "$$IoU = \\frac{TP}{TP + FP + FN}$$\n",
        "\n",
        "Where TP is the number of true positives, FP is the number of false positives, and FN is the number of false negatives.\n",
        "\n",
        "Really all this boils down to is looking at how close our predicted labels, if we made every background cluster pixel black, and every foreground cluster pixel 1, is to our ground-truth mask.\n",
        "\n",
        "### Task 03-1: Code (1 pt.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQqxBfvSGrO8"
      },
      "outputs": [],
      "source": [
        "def calculate_segmentation_metrics(pred, truth, visualize=False):\n",
        "    \"\"\"\n",
        "    Calculate Intersection over Union (IoU) to measure segmentation accuracy\n",
        "\n",
        "    Args:\n",
        "        pred: Binary prediction mask (595, 420)\n",
        "        truth: Binary ground truth mask (595, 420)\n",
        "\n",
        "\n",
        "    Returns:\n",
        "        iou: Intersection over Union (IoU) metric\n",
        "    \"\"\"\n",
        "    if visualize:\n",
        "      # Visualize the masks\n",
        "      plt.figure(figsize=(10, 5))\n",
        "\n",
        "      plt.subplot(1, 2, 1)\n",
        "      plt.title('Prediction Mask')\n",
        "      plt.imshow(pred, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "      plt.subplot(1, 2, 2)\n",
        "      plt.title('Ground Truth Mask')\n",
        "      plt.imshow(truth, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "      plt.show()\n",
        "\n",
        "    # TODO: Calculate intersection and union\n",
        "\n",
        "    # TODO: calculate IoU (Intersection over Union)\n",
        "    #    hint: this is also known as the Jaccard index\n",
        "\n",
        "    return iou"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7_iGD1HrxAZ"
      },
      "source": [
        "### Task 03-2: Description (0 pts.)\n",
        "#### Evaluation of Unsupervised Methods\n",
        "\n",
        "Now that we have a way to measure how well our clustering worked, we should probably evaluate all of our different methods and combinations we could use. In order to test your implementations of PCA and kmeans, we're going to compare them against the versions of them in the sklearn library. It would be pretty cool if your code worked just as well as what people use on the job!\n",
        "\n",
        "In addition to trying the different implementations, we should probably test a couple different levels of explained variance for PCA to see how they stack up. We're going to test: `0.75, 0.9, and 0.99`\n",
        "One would assume that 0.99 will yield the best results, but it will be interesting to see the differences between them!\n",
        "\n",
        "**[NOTE]:** Since there are a lot of different combinations, I included some helper print functions to better format the output (at least on my monitor, which is pretty wide)\n",
        "\n",
        "### Task 03-2: Helper Code (0 pts.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def header_printer(i):\n",
        "    print(f\"Image {i+1}:\")\n",
        "    print('#' * 80)\n",
        "    print()\n",
        "    print(' ' * 25 + 'EV: 0.75' + ' ' * 40 + 'EV: 0.9' + ' ' * 40 + 'EV: 0.99')\n",
        "    headers = ' ' * 14 + \"Student kmeans\" + ' ' * 5 + \"sklearn kmeans\"\n",
        "    print(headers * 3)\n",
        "\n",
        "def row_formatter(ious):\n",
        "    return f'{ious[0]:.4f}' + ' ' * 12 + f'{ious[1]:.4f}' + ' ' * 23 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 03-2: Code (1 pt.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfDzIAU2GrO9",
        "outputId": "cafd4898-1ec1-4023-9e53-9e1009a86e28"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.decomposition import PCA as sklearn_pca\n",
        "from sklearn.cluster import KMeans as sklearn_kmeans\n",
        "\n",
        "print(\"\\nEvaluating Unsupervised Segmentation Methods...\")\n",
        "print('#' * 80)\n",
        "print()\n",
        "\n",
        "# Initialize pca methods and kmeans methods\n",
        "pca_implementations = {'Student PCA': PCA, 'sklearn PCA': sklearn_pca}\n",
        "kmeans_implementations = {'Student kmeans': kmeans(n_clusters=2, random_state=42), 'sklearn kmeans': sklearn_kmeans(n_clusters=2, init='random', random_state=42)}\n",
        "\n",
        "for i, image in enumerate(images):\n",
        "    header_printer(i)\n",
        "\n",
        "    for pca_creator, pca_method in pca_implementations.items():\n",
        "        results = ' ' * 8\n",
        "\n",
        "        for offset, ev in enumerate([0.75, 0.9, .99]):\n",
        "            ious = []\n",
        "            for kmeans_creator, kmeans_method in kmeans_implementations.items():\n",
        "                # Reshape the image into a 2D array of pixels and 3 color values (RGB)\n",
        "                pixels = image.reshape(-1, 3)          # reshaped into a 2D array where each row represents a pixel and the columns represent the RGB color channels\n",
        "                                                    # Note: The -1 means \"reshape it into as many rows as needed\" (i.e., one row per pixel), and 3 is the number of columns corresponding to the RGB channels\n",
        "\n",
        "                # TODO: Apply PCA to reduce dimensionality\n",
        "\n",
        "                # TODO: Perform K-Means clustering, fit Kmeans to data to get cluster labels for each pixel\n",
        "\n",
        "                # Reshape the labels back to the image shape\n",
        "                segmented_image = labels.reshape(image.shape[:2])\n",
        "\n",
        "                # Calculate IoU to evaluate clustering\n",
        "                ious.append(calculate_segmentation_metrics(segmented_image.astype(bool), masks[i].astype(bool)))\n",
        "\n",
        "            results += row_formatter(ious)\n",
        "        print(f\"{pca_creator + results}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ5HJXXRrxAZ"
      },
      "source": [
        "### Task 03-2: Expected Output (0 pts.)\n",
        "\n",
        "```\n",
        "Evaluating Unsupervised Segmentation Methods...\n",
        "################################################################################\n",
        "\n",
        "Image 1:\n",
        "################################################################################\n",
        "\n",
        "                         EV: 0.75                                        EV: 0.9                                        EV: 0.99\n",
        "              Student kmeans     sklearn kmeans              Student kmeans     sklearn kmeans              Student kmeans     sklearn kmeans\n",
        "Student PCA        0.8446            0.8446                       0.8464            0.8464                       0.8468            0.8468                       \n",
        "sklearn PCA        0.8446            0.8446                       0.8464            0.8464                       0.8468            0.8468                       \n",
        "\n",
        "Image 2:\n",
        "################################################################################\n",
        "\n",
        "                         EV: 0.75                                        EV: 0.9                                        EV: 0.99\n",
        "              Student kmeans     sklearn kmeans              Student kmeans     sklearn kmeans              Student kmeans     sklearn kmeans\n",
        "Student PCA        0.8208            0.8208                       0.8159            0.8158                       0.8160            0.8159                       \n",
        "sklearn PCA        0.8208            0.8208                       0.8159            0.8158                       0.8160            0.8159                       \n",
        "\n",
        "Image 3:\n",
        "################################################################################\n",
        "\n",
        "                         EV: 0.75                                        EV: 0.9                                        EV: 0.99\n",
        "              Student kmeans     sklearn kmeans              Student kmeans     sklearn kmeans              Student kmeans     sklearn kmeans\n",
        "Student PCA        0.8012            0.0281                       0.8032            0.0278                       0.8036            0.0278                       \n",
        "sklearn PCA        0.8012            0.0281                       0.8032            0.0278                       0.8036            0.0278                       \n",
        "\n",
        "Image 4:\n",
        "################################################################################\n",
        "\n",
        "                         EV: 0.75                                        EV: 0.9                                        EV: 0.99\n",
        "              Student kmeans     sklearn kmeans              Student kmeans     sklearn kmeans              Student kmeans     sklearn kmeans\n",
        "Student PCA        0.8489            0.8489                       0.8509            0.8507                       0.8512            0.8510                       \n",
        "sklearn PCA        0.8489            0.8489                       0.8509            0.8507                       0.8512            0.8510    \n",
        "```\n",
        "\n",
        "### Task 03-3: Short Answer Questions (2 pts.)\n",
        "\n",
        "* Task 03-3-1: Why do you think, for Image 3, the sklearn IoU was so much smaller than the others?\n",
        "    * **[ANSWER]**\n",
        "\n",
        "* Task 03-3-2: How many features did our feature vectors actually have? What were they?\n",
        "    * **[ANSWER]**\n",
        "\n",
        "### *Story Progression*\n",
        "\n",
        "The unsupervised segmentation seems to work pretty well, but you wonder if a supervised method might work even better. We could probably set this up in a similar way to the clustering task, but instead of using two clusters (foreground and background), we can have two classes (foreground and background).\n",
        "\n",
        "Luckily the police have manually created a binary mask for us that we can use as labelled data to train our supervised model.\n",
        "\n",
        "Unluckily, we need to somehow let each pixel know about the surrounding pixels. So we'll need to somehow create a feature vector for each pixel that contains information about the pixel and the surrounding pixels.\n",
        "\n",
        "Maybe we can take a patch around each pixel and use the RGB values of the pixels in the patch as features?\n",
        "\n",
        "## Task 04: Supervised Image Segmentation\n",
        "### Task 04-1: Description (0 pts.)\n",
        "#### Feature Vector Extraction\n",
        "\n",
        "To train our SVM, we need to create some features. In Homework02 you had to create some features that could describe the evening that a person had, and you used things like time spent in each room and how their activities related to weapons. In this homework, you need to design a feature to describe a pixel. Usually when doing Computer Vision (CV) it's useful for a feature vector for a specific pixel to also include some information about what the surrounding pixels look like.\n",
        "\n",
        "In the block below, you'll write a function to extract feature vectors for each pixel, taking into account a \"patch\" of surrounding pixels.\n",
        "\n",
        "### Task 04-1: Code (2 pts.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqH-pU1mGrO8"
      },
      "outputs": [],
      "source": [
        "def extract_features(image, patch_size=5):\n",
        "    \"\"\"\n",
        "    Extract features for each pixel using RGB values and local neighborhood.\n",
        "\n",
        "    Args:\n",
        "        image: RGB image (595, 420, 3)\n",
        "        patch_size: Size of the local neighborhood patch (must be odd)\n",
        "\n",
        "    Returns:\n",
        "        features: Array of shape (n_pixels, n_features) (249900, 78) (595 x 420, 5 x 5 x 3 + 1 x 3)\n",
        "    \"\"\"\n",
        "    height, width, channels = image.shape\n",
        "\n",
        "    # Add padding to image\n",
        "    padding = patch_size // 2\n",
        "\n",
        "    padded = cv2.copyMakeBorder(\n",
        "        image,\n",
        "        padding, padding, padding, padding,\n",
        "        cv2.BORDER_REFLECT\n",
        "    )\n",
        "\n",
        "    # TODO: Calculate total number of pixels\n",
        "\n",
        "    # TODO: Calculate total number of features per pixel\n",
        "\n",
        "    # TODO: Initialize data structue to store features for all pixels\n",
        "\n",
        "    # TODO: Loop through pixels and extracts features for each pixel\n",
        "    #     hint: the feature vector will be all RGB values for every surrounding pixel concatenated with the pixel itself\n",
        "    #     hint: this results in a 78 dimensional feature vector, for each pixel!\n",
        "    #     hint: 5 x 5 patch = 25, 3 colors per pixel gives 3 x 25 = 75 + 3 for the pixel itself again gives 78\n",
        "    #     hint: use current pixel RGB values and the surrounding local patch\n",
        "    pixel_idx = 0\n",
        "\n",
        "    # Return feature matrix\n",
        "    return features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 04-2: Description (0 pts.)\n",
        "#### SVM Segmentation Helper Function\n",
        "\n",
        "Now that we have out feature extractor, lets also write a small helper function that will take a trained SVM, an initialized PCA, and a test image a return the test image after segmenting it with our model.\n",
        "\n",
        "### Task 04-2: Code (1 pt.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3oaFW1YGrO8"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import cudf\n",
        "    from cuml.svm import SVC, LinearSVC\n",
        "except:\n",
        "    from sklearn.svm import SVC, LinearSVC\n",
        "\n",
        "# -------------------------------------\n",
        "# Task 5: SVM Segmentation\n",
        "# -------------------------------------\n",
        "def svm_segmentation(model, pca, test_image):\n",
        "    # TODO: Extract features of testing image\n",
        "\n",
        "    # TODO: Apply transformations to testing image if PCA != None\n",
        "    #     hint: transformations means scaling and dimensionality reduction\n",
        "\n",
        "    # Attempt to move test features to GPU\n",
        "    try:\n",
        "        X_test = cudf.DataFrame.from_records(X_test)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # TODO: Predict on test image\n",
        "\n",
        "    # Attempt to retrieve results from GPU\n",
        "    try:\n",
        "        predictions = predictions.to_cupy().get()  # get() brings it to CPU as np.ndarray\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Reshape predictions to match image matrix shape\n",
        "    segmented_image = predictions.reshape(test_image.shape[:2])\n",
        "\n",
        "    return segmented_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 04-3: Description (0 pts.)\n",
        "#### Properly set colab env\n",
        "\n",
        "**[WARNING]:** Colab only gives limited GPU runtime to users, and it takes quite some time to refresh. I would recommend you first test and debug your code with the linear kernel on the CPU environment to first make sure you can actually produce results, and only switch to the GPU environment when you're planning on doing your final run-through.\n",
        "\n",
        "SVMs are very very slow for large datasets (which these images count as). In order to make your evaluations run faster, we will use an implementation of the SVM that can run on the GPU, making it much more efficient. Colab gives free (limited) access to GPUs. You can follow the steps below to change your environment to be one with a GPU.\n",
        "\n",
        "1. Select the `Change runtime type` from the environment dropdown in the upper right\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/nd-cse-30124-fa25/nd-cse-30124-fa25.github.io/refs/heads/main/static/img/hw03/change_runtime_2.png\" alt=\"Map\" style=\"width: 100%; max-width: 800px; height: auto;\">\n",
        "\n",
        "2. Select t4 GPU as your environment\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/nd-cse-30124-fa25/nd-cse-30124-fa25.github.io/refs/heads/main/static/img/hw03/change_runtime_1.png\" alt=\"Map\" style=\"width: 100%; max-width: 800px; height: auto;\">\n",
        "\n",
        "\n",
        "\n",
        "**[WARNING]:** If you're not running this on colab it will likely be very slow. My code took 24m 33.9s to complete on my mac mini in my office and if you're on your laptop it will likely be even slower.\n",
        "You could theoretically install CuML yourself (but it's not compatible with macos for some ungodly reason) if you wanted to work locally by running:\n",
        "\n",
        "```\n",
        "pip install cudf\n",
        "pip install cuml\n",
        "```\n",
        "\n",
        "### Task 04-4: Description (0 pts.)\n",
        "#### Supervised Segmentation Evaluation \n",
        "\n",
        "Much like with the unsupervised segmentation, we have a couple different options that we can tweak for our supervised model. We can try different combinations of kernels and components. You should test `[0.75, 0.9, 1.0]` for PCA (we will use only your implementation of it) and for the kernels you should test `['linear', 'poly', 'rbf']`. Usually `rbf` is the best one but it's important to actually test it!\n",
        "\n",
        "### Task 04-4: Code (2 pts.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0vR5UhmGrO9",
        "outputId": "09c8cd2c-69b7-4b30-f2e1-ec11a2603162"
      },
      "outputs": [],
      "source": [
        "print(\"Evaluating Supervised Segmentation Methods...\")\n",
        "print('#' * 80)\n",
        "print()\n",
        "\n",
        "# We only use the first 1000 pixels from the training image and mask, otherwise it takes too long to train\n",
        "# We'll train on only the first 1000 pixels from the first image, and test only on the second (again for sake of runtimes)\n",
        "# Really we should be doing some 4 fold cross validation with full images here but I don't want to wait 9 hours for it to run\n",
        "train_image = images[0][:1000]\n",
        "train_mask = masks[0][:1000]\n",
        "\n",
        "test_image = images[1]\n",
        "test_mask = masks[1]\n",
        "\n",
        "# TODO: Extract features of training image\n",
        "\n",
        "y_train = (train_mask > 0).reshape(-1)\n",
        "\n",
        "# TODO: Declare the kernels we want to test\n",
        "for kernel in []: \n",
        "    print(f\"Testing an SVM with a {kernel} kernel:\")\n",
        "\n",
        "    # TODO: Declare the explained variances we want to test\n",
        "    for ev in []:\n",
        "        # TODO: Apply PCA\n",
        "\n",
        "        # Attempt to move to GPU (as cuDF)\n",
        "        try:\n",
        "            X_train_pca = cudf.DataFrame.from_records(X_train_pca)\n",
        "            y_train = cudf.Series(y_train)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # TODO: Initialize the SVM using LinearSVC for the linear kernel and SVC for everything else\n",
        "\n",
        "        # TODO: Fit the SVM to the training data\n",
        "\n",
        "        # TODO: segment the test image and calculate the IoU for it compared to the test mask\n",
        "        \n",
        "        print(f\"\\tAn explained variance of {ev} results in an IoU of {iou:.2f}\")\n",
        "\n",
        "    print()\n",
        "    print('#' * 80)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6DMANXwrxAa"
      },
      "source": [
        "### Task 04-3: Expected Output (1 pt.)\n",
        "\n",
        "```\n",
        "Evaluating Supervised Segmentation Methods...\n",
        "################################################################################\n",
        "\n",
        "Testing an SVM with a linear kernel:\n",
        "\tAn explained variance of 0.75 results in an IoU of 0.82\n",
        "\tAn explained variance of 0.9 results in an IoU of 0.83\n",
        "\tAn explained variance of 1.0 results in an IoU of 0.86\n",
        "\n",
        "################################################################################\n",
        "\n",
        "Testing an SVM with a poly kernel:\n",
        "\tAn explained variance of 0.75 results in an IoU of 0.84\n",
        "\tAn explained variance of 0.9 results in an IoU of 0.89\n",
        "\tAn explained variance of 1.0 results in an IoU of 0.93\n",
        "\n",
        "################################################################################\n",
        "\n",
        "Testing an SVM with a rbf kernel:\n",
        "\tAn explained variance of 0.75 results in an IoU of 0.90\n",
        "\tAn explained variance of 0.9 results in an IoU of 0.95\n",
        "\tAn explained variance of 1.0 results in an IoU of 0.98\n",
        "\n",
        "################################################################################\n",
        "```\n",
        "\n",
        "### Task 04-4: Short Answer Questions (2 pts.)\n",
        "\n",
        "* Task 04-4-1: What is it about SVMs that make them very slow (*Hint:* It has to do with the dual-form equation)?\n",
        "\t* **[ANSWER]**\n",
        "\n",
        "* Task 04-4-2: Do you think increasing the patch size of our features would make our results better?\n",
        "\t* **[ANSWER]**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJfoj49OrxAa"
      },
      "source": [
        "## Task 05: Region Extraction\n",
        "### Task 05-1: Description (0 pts.)\n",
        "#### Region localization from SVM image segmentation\n",
        "\n",
        "Now that we have a best model, we can actually segment our pages and extract each letter! This computer vision stuff is outside the scope of this course, so the code is just provided for you. But this is how we can extract the region of each letter using our segmentation!\n",
        "\n",
        "### Task 05-1: Code (0 pts.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXJHmdgqGrO-"
      },
      "outputs": [],
      "source": [
        "from skimage.measure import label, regionprops\n",
        "import os\n",
        "\n",
        "def extract_and_save_letters(segmented_image, original_image, page, output_dir='letters'):\n",
        "    \"\"\"\n",
        "    Extract each segmented letter and save as a separate PNG file.\n",
        "\n",
        "    Args:\n",
        "        segmented_image: Segmented image with unique labels for each letter\n",
        "        original_image: Original RGB image\n",
        "        output_dir: Directory to save the extracted letter images\n",
        "    \"\"\"\n",
        "    # Ensure the output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Label connected components\n",
        "    labeled_image = label(segmented_image)\n",
        "\n",
        "    # Iterate over each labeled region\n",
        "    for region in regionprops(labeled_image):\n",
        "        # Extract the bounding box of the region\n",
        "        min_row, min_col, max_row, max_col = region.bbox\n",
        "\n",
        "        # Extract the region from the original image\n",
        "        letter_image = original_image[min_row:max_row, min_col:max_col]\n",
        "\n",
        "        # Save the extracted letter as a PNG file\n",
        "        letter_filename = os.path.join(output_dir, f'note_{page}_letter_{region.label}.png')\n",
        "        cv2.imwrite(letter_filename, cv2.cvtColor(letter_image, cv2.COLOR_RGB2BGR))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR_ub3n1rxAa"
      },
      "source": [
        "### Task 05-2: Description (0 pts.)\n",
        "#### Extract each character from our letters\n",
        "\n",
        "Lets actually use our best combination to extract each letter as a png!\n",
        "\n",
        "**[WARNING]:** Much like the SVM, this took a while to run, for me it took about 10m 50s on my mac mini again\n",
        "\n",
        "### Task 05-2: Code (0 pts.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Au56gvNRqJUl"
      },
      "outputs": [],
      "source": [
        "# Attempt to move to GPU (as cuDF)\n",
        "try:\n",
        "    X_train = cudf.DataFrame.from_records(X_train)\n",
        "    y_train = cudf.Series(y_train)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "svm = SVC(kernel='rbf')\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "for page, image in enumerate(images):\n",
        "    segmented_image = svm_segmentation(svm, None, image)\n",
        "    extract_and_save_letters(segmented_image, image, page)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 05-2: Example Output (0 pts.)\n",
        "\n",
        "Since there are 262 characters across all 4 pages of the note, I won't show all of the output, but here are the letters my code extracted from the first line of the first page:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/nd-cse-30124-fa25/nd-cse-30124-fa25.github.io/refs/heads/main/static/img/hw03/note_0_letter_1.png\" alt=\"Map\" style=\"width: 10%; max-width: 800px; height: auto;\">\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/nd-cse-30124-fa25/nd-cse-30124-fa25.github.io/refs/heads/main/static/img/hw03/note_0_letter_4.png\" alt=\"Map\" style=\"width: 10%; max-width: 800px; height: auto;\">\n",
        "<img src=\"https://raw.githubusercontent.com/nd-cse-30124-fa25/nd-cse-30124-fa25.github.io/refs/heads/main/static/img/hw03/note_0_letter_2.png\" alt=\"Map\" style=\"width: 10%; max-width: 800px; height: auto;\">\n",
        "<img src=\"https://raw.githubusercontent.com/nd-cse-30124-fa25/nd-cse-30124-fa25.github.io/refs/heads/main/static/img/hw03/note_0_letter_3.png\" alt=\"Map\" style=\"width: 10%; max-width: 800px; height: auto;\">\n",
        "<img src=\"https://raw.githubusercontent.com/nd-cse-30124-fa25/nd-cse-30124-fa25.github.io/refs/heads/main/static/img/hw03/note_0_letter_5.png\" alt=\"Map\" style=\"width: 10%; max-width: 800px; height: auto;\">\n",
        "<img src=\"https://raw.githubusercontent.com/nd-cse-30124-fa25/nd-cse-30124-fa25.github.io/refs/heads/main/static/img/hw03/note_0_letter_6.png\" alt=\"Map\" style=\"width: 10%; max-width: 800px; height: auto;\">\n",
        "\n",
        "### *Story Progression*\n",
        "\n",
        "WOW! We did it, we used AI to take in an image of a ransom note, figure out where each individual letter was, and created a cropped image of each one!\n",
        "\n",
        "Now that we have all of the letters extracted, we can perform Optical Character Recognition (OCR) on each letter. OCR is the process of taking in a picture of a character and returning the actual ascii character it represents (think MNIST).\n",
        "\n",
        "While the police want the data ASAP, you know you need a break for a lil drinky-poo. The police will have to wait, but in the next homework you'll explore how to do OCR on your extracted letters with a basic Feed-Forward Neural Network (which you'll be writing from scratch) and a Convolutional Neural Network (which you'll be using from PyTorch)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.9.6)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
