{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a939c113",
   "metadata": {},
   "source": [
    "# Introduction to Artificial Intelligence - Homework Assignment 03 (20pts.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VnxyrBUWGrO3",
   "metadata": {},
   "source": [
    "* NETIDs:\n",
    "\n",
    "This assignment covers the following topics:\n",
    "\n",
    "* Principle Component Analysis\n",
    "* KMeans Clustering\n",
    "* Agglomerative Clustering\n",
    "* Gaussian Mixture Models\n",
    "* Support Vector Machines\n",
    "\n",
    "and will consist of 5 tasks:\n",
    "\n",
    "* Task 00: Load Dataset (0 pts.)\n",
    "* Task 01: PCA Function\n",
    "* Task 02: Clustering\n",
    "    * Task 02-1: KMeans Clustering\n",
    "    * Task 02-2: Agglomerative Clustering\n",
    "    * Task 02-3: Gaussian Mixture Model Clustering\n",
    "* Task 03: Clustering Method Evaluation\n",
    "    * Task 03-1: IoU Metric\n",
    "    * Model Evaluation\n",
    "* Task 04: Support Vector Machines\n",
    "    * Task 04-1: Feature vectors creation for SVM\n",
    "    * Task 04-2: Support Vector Machines\n",
    "    * Task 04-3: SVM Evaluation\n",
    "* Task 05: Final Letter Data Extraction\n",
    "    * Task 05-1: Computer Vision Region Cropping Function\n",
    "    * Task 05-2: Letter Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homework-3-encoded-letters",
   "metadata": {},
   "source": [
    "### *Story Progression*\n",
    "\n",
    "The police need some help with those letters Detective Caulfield\n",
    "delivered during class. The letters appear to be newspaper cutouts all\n",
    "combined together into a single letter. The Police don't want to do all\n",
    "the manual work of converting the letters into a text format and so\n",
    "they've asked your your help!\n",
    "\n",
    "As you try to fight off the spring break hangover, you realize you can\n",
    "treat this as an image segmentation task. We need to figure out where in\n",
    "the entire image each letter is. After hairing the dog, you have another\n",
    "breakthrough idea, what if you just perform a clustering task with only\n",
    "two clusters, foreground and background? Using the clustering methods we\n",
    "saw in class, you decide to give it a shot!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loading-data",
   "metadata": {},
   "source": [
    "## Task 00: Load Dataset\n",
    "### Task 00: Description\n",
    "#### Dataset Loading\n",
    "\n",
    "We can use the imread function from the cv2 library to read our images\n",
    "in. We should end up with the actual images shape being (595, 420, 3)\n",
    "and the mask shape being (595, 420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uX4fvw_aGrO9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Set random seed for NumPy’s random number generator\n",
    "#     Conceptually: makes random operations (e.g., random initialization in KMeans, shuffling data, or selecting random samples) produce the same results every time the code is run\n",
    "#     aka your code becomes reporducable\n",
    "np.random.seed(42)\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    REPO_URL = \"https://github.com/nd-cse-30124-fa25/cse-30124-homeworks.git\"\n",
    "    REPO_NAME = \"cse-30124-homeworks\"\n",
    "    HW_FOLDER = \"homework03\" \n",
    "\n",
    "    # Clone repo if not already present\n",
    "    if not os.path.exists(REPO_NAME):\n",
    "        !git clone {REPO_URL}\n",
    "\n",
    "    # cd into the homework folder\n",
    "    %cd {REPO_NAME}/{HW_FOLDER}\n",
    "\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "image_1_path = 'letters/note_page_1.png'\n",
    "mask_1_path = 'letters/mask_page_1.png'\n",
    "\n",
    "image_2_path = 'letters/note_page_2.png'\n",
    "mask_2_path = 'letters/mask_page_2.png'\n",
    "\n",
    "image_3_path = 'letters/note_page_3.png'\n",
    "mask_3_path = 'letters/mask_page_3.png'\n",
    "\n",
    "image_4_path = 'letters/note_page_4.png'\n",
    "mask_4_path = 'letters/mask_page_4.png'\n",
    "\n",
    "\n",
    "image_1 = cv2.imread(image_1_path)\n",
    "image_1 = cv2.cvtColor(image_1, cv2.COLOR_BGR2RGB)\n",
    "mask_1 = cv2.imread(mask_1_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "image_2 = cv2.imread(image_2_path)\n",
    "image_2 = cv2.cvtColor(image_2, cv2.COLOR_BGR2RGB)\n",
    "mask_2 = cv2.imread(mask_2_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "image_3 = cv2.imread(image_3_path)\n",
    "image_3 = cv2.cvtColor(image_3, cv2.COLOR_BGR2RGB)\n",
    "mask_3 = cv2.imread(mask_3_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "image_4 = cv2.imread(image_4_path)\n",
    "image_4 = cv2.cvtColor(image_4, cv2.COLOR_BGR2RGB)\n",
    "mask_4 = cv2.imread(mask_4_path, cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsupervised-learning-image-segmentation",
   "metadata": {},
   "source": [
    "### *Story Progression*\n",
    "\n",
    "You remember there were a number of clustering methods in class, but you\n",
    "also remember that typically k-means clustering was the one used as a\n",
    "sort of litmus test, so you figure that may as well be the place to\n",
    "start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfb8313",
   "metadata": {},
   "source": [
    "## Task 01: Principal Component Analysis\n",
    "### Task 01: Description\n",
    "#### PCA\n",
    "\n",
    "*Add more instructions*\n",
    "\n",
    "### Task 01: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debabbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class PCA:\n",
    "    def __init__(self, n_components=None, whiten=False):\n",
    "        \"\"\"\n",
    "        n_components:\n",
    "          - None  -> keep all components\n",
    "          - int   -> keep that many components\n",
    "          - float in (0,1] -> keep the minimum # of components to reach this\n",
    "                              fraction of explained variance\n",
    "        whiten: if True, projected features are scaled to unit variance.\n",
    "        \"\"\"\n",
    "        self.n_components = n_components\n",
    "        self.whiten = whiten\n",
    "\n",
    "    def fit(self, X):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Center the data\n",
    "        self.mean_ = X.mean(axis=0)\n",
    "        Xc = X - self.mean_\n",
    "\n",
    "        # SVD: Xc = U * diag(S) * Vt\n",
    "        U, S, Vt = np.linalg.svd(Xc, full_matrices=False)\n",
    "\n",
    "        # Variances along principal axes\n",
    "        self.singular_values_ = S\n",
    "        self.explained_variance_ = (S**2) / (n_samples - 1)\n",
    "        total_var = self.explained_variance_.sum()\n",
    "        self.explained_variance_ratio_ = self.explained_variance_ / total_var\n",
    "\n",
    "        # Decide how many to keep\n",
    "        self.n_components_ = self._resolve_n_components(X.shape[1])\n",
    "\n",
    "        # Principal axes (each row is a component loading vector)\n",
    "        self.components_ = Vt[:self.n_components_]\n",
    "        return self\n",
    "\n",
    "    def _resolve_n_components(self, n_features):\n",
    "        if self.n_components is None:\n",
    "            return min(n_features, self.singular_values_.size)\n",
    "        if isinstance(self.n_components, int):\n",
    "            k = int(self.n_components)\n",
    "            if not (1 <= k <= min(n_features, self.singular_values_.size)):\n",
    "                raise ValueError(\"n_components out of valid range.\")\n",
    "            return k\n",
    "        if isinstance(self.n_components, float):\n",
    "            thr = float(self.n_components)\n",
    "            if not (0.0 < thr <= 1.0):\n",
    "                raise ValueError(\"Float n_components must be in (0, 1].\")\n",
    "            cumsum = np.cumsum(self.explained_variance_ratio_)\n",
    "            return int(np.searchsorted(cumsum, thr) + 1)\n",
    "        raise TypeError(\"n_components must be None, int, or float in (0,1].\")\n",
    "\n",
    "    def transform(self, X):\n",
    "        self._check_fitted()\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        Xc = X - self.mean_\n",
    "        Z = Xc @ self.components_.T\n",
    "        if self.whiten:\n",
    "            Z /= np.sqrt(self.explained_variance_[:self.n_components_] + 1e-12)\n",
    "        return Z\n",
    "\n",
    "    def inverse_transform(self, Z):\n",
    "        self._check_fitted()\n",
    "        Z = np.asarray(Z, dtype=float)\n",
    "        if self.whiten:\n",
    "            Z *= np.sqrt(self.explained_variance_[:self.n_components_] + 1e-12)\n",
    "        Xhat = Z @ self.components_ + self.mean_\n",
    "        return Xhat\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        return self.fit(X).transform(X)\n",
    "\n",
    "    def _check_fitted(self):\n",
    "        if not hasattr(self, \"components_\"):\n",
    "            raise RuntimeError(\"Call fit(X) before transform/inverse_transform.\")\n",
    "\n",
    "# ---------------------------\n",
    "# Tiny usage example\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    rng = np.random.default_rng(0)\n",
    "    # Make a 3D dataset with correlated features\n",
    "    n = 400\n",
    "    base = rng.normal(0, 1, size=(n, 1))\n",
    "    x1 = base[:, 0] + 0.1 * rng.normal(size=n)\n",
    "    x2 = 2 * base[:, 0] + 0.1 * rng.normal(size=n)\n",
    "    x3 = rng.normal(0, 0.3, size=n)  # mostly noise\n",
    "    X = np.c_[x1, x2, x3]\n",
    "\n",
    "    pca = PCA(n_components=0.95)   # keep enough PCs to explain ≥95% variance\n",
    "    Z = pca.fit_transform(X)\n",
    "\n",
    "    print(\"n_components_:\", pca.n_components_)\n",
    "    print(\"Explained variance ratio:\", pca.explained_variance_ratio_[:pca.n_components_])\n",
    "    # Reconstruct to see the compression error\n",
    "    X_recon = pca.inverse_transform(Z)\n",
    "    recon_mse = np.mean((X - X_recon)**2)\n",
    "    print(\"Reconstruction MSE:\", recon_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4cd033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pca(x, n_components=2):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9eea6f",
   "metadata": {},
   "source": [
    "## Task 02: KMeans Clustering\n",
    "### Task 02: Description\n",
    "#### KMeans Clustering\n",
    "\n",
    "*Add more instructions*\n",
    "\n",
    "### Task 02: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jIv8fyr5GrO7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------\n",
    "# Task 1: Perform Kmeans Segmentation\n",
    "# -------------------------------------\n",
    "def kmeans_segmentation(image, pca_components=None):\n",
    "    \"\"\"\n",
    "    Perform K-Means segmentation on an image\n",
    "\n",
    "    Args:\n",
    "        image: RGB image\n",
    "        pca_components: Number of PCA components to use (None for no PCA)\n",
    "\n",
    "    Returns:\n",
    "        segmented_image: Image with pixel values replaced by cluster labels\n",
    "    \"\"\"\n",
    "    # Reshape the image into a 2D array of pixels and 3 color values (RGB)\n",
    "    pixels = image.reshape(-1, 3)\n",
    "\n",
    "    # Apply PCA if specified\n",
    "    if pca_components is not None:\n",
    "        # TODO: Standardize pixel values to have zero mean and unit variance\n",
    "\n",
    "\n",
    "        # TODO: Apply PCA to reduce dimensionality\n",
    "\n",
    "\n",
    "        # TODO: Assign PCA-transformed data to X\n",
    "        X = ...\n",
    "    else:\n",
    "        # If no PCA wanted, just set X = to the reshaped image\n",
    "        X = ...\n",
    "\n",
    "    # TODO: Perform K-Means clustering, fit Kmeans to data to get cluster labels for each pixel\n",
    "    #    hint, we want to cluster the foreground and the background, so how many clusers should you use?\n",
    "\n",
    "    # Reshape the labels back to the image shape\n",
    "    segmented_image = labels.reshape(image.shape[:2])\n",
    "\n",
    "    return segmented_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3a411a",
   "metadata": {},
   "source": [
    "## Task 03: Agglomerative Hierarchical Clustering\n",
    "### Task 03: Description\n",
    "#### Hierarchical Clustering\n",
    "\n",
    "*Add more instructions*\n",
    "\n",
    "#### *NOTE: This will likely crash your kernel, it's a pedagogical tool.*\n",
    "\n",
    "### Task 03: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5JW64tzGrO7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------\n",
    "# Task 2: Perform Agglomerative Segmentation\n",
    "# -------------------------------------\n",
    "def agglomerative_segmentation(image, pca_components=None):\n",
    "    \"\"\"\n",
    "    Perform Agglomerative Clustering on an image\n",
    "\n",
    "    Args:\n",
    "        image: RGB image\n",
    "        pca_components: Number of PCA components to use (None for no PCA)\n",
    "\n",
    "    Returns:\n",
    "        segmented_image: Image with pixel values replaced by cluster labels\n",
    "    \"\"\"\n",
    "\n",
    "    # Reshape the image into a 2D array of pixels and 3 color values (RGB)\n",
    "    pixels = image.reshape(-1, 3)\n",
    "\n",
    "    # Apply PCA if specified\n",
    "    if pca_components is not None:\n",
    "        # TODO: Standardize pixel values to have zero mean and unit variance\n",
    "\n",
    "\n",
    "        # TODO: Apply PCA to reduce dimensionality\n",
    "\n",
    "\n",
    "        # TODO: Assign PCA-transformed data to X\n",
    "        X = ...\n",
    "    else:\n",
    "        X = ...\n",
    "\n",
    "    # TODO: Apply Agglomerative Clustering\n",
    "\n",
    "\n",
    "    # Reshape the labels back to the image shape\n",
    "    segmented_image = labels.reshape(image.shape[:2])\n",
    "\n",
    "    return segmented_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a29d9c",
   "metadata": {},
   "source": [
    "### Task03: Short Answer Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75be1cf",
   "metadata": {},
   "source": [
    "## Task 04: Gaussian Mixture Models\n",
    "### Task 04: Description\n",
    "#### GMMs\n",
    "\n",
    "*Add more instructions*\n",
    "\n",
    "### Task 04: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GxMPw2HcGrO7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------\n",
    "# Task 3: Perform Gaussian Mixture Model Segmentation\n",
    "# -------------------------------------\n",
    "def gmm_segmentation(image, pca_components=None):\n",
    "    \"\"\"\n",
    "    Perform Gaussian Mixture Model segmentation on an image\n",
    "\n",
    "    Args:\n",
    "        image: RGB image\n",
    "        pca_components: Number of PCA components to use (None for no PCA)\n",
    "\n",
    "    Returns:\n",
    "        segmented_image: Image with pixel values replaced by component labels\n",
    "    \"\"\"\n",
    "\n",
    "    # Reshape the image into a 2D array of pixels and 3 color values (RGB)\n",
    "    pixels = image.reshape(-1, 3)\n",
    "\n",
    "    # Apply PCA if specified\n",
    "    if pca_components is not None:\n",
    "        # TODO: Standardize pixel values to have zero mean and unit variance\n",
    "\n",
    "\n",
    "        # TODO: Apply PCA to reduce dimensionality\n",
    "\n",
    "\n",
    "        # TODO: Assign PCA-transformed data to X\n",
    "        X = ...\n",
    "    else:\n",
    "        X = ...\n",
    "\n",
    "    # TODO: Apply GMM\n",
    "\n",
    "\n",
    "    # Reshape the labels back to the image shape\n",
    "    segmented_image = labels.reshape(image.shape[:2])\n",
    "\n",
    "    return segmented_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9419f16e",
   "metadata": {},
   "source": [
    "## Task 05: Clustering Evaluation\n",
    "### Task 05-1: Description\n",
    "#### Intersection over Union (IoU)\n",
    "\n",
    "We'll need to evaluate how well our segmentation methods are doing. We\n",
    "can use the intersection over union (IoU) metric to evaluate how well\n",
    "our segmentation methods are doing.\n",
    "\n",
    "Intersection over Union (IoU) is defined as the intersection of the\n",
    "predicted mask and the ground truth mask divided by the union of the\n",
    "predicted mask and the ground truth mask.\n",
    "\n",
    "<span class=\"math display\">\\$\\$IoU = \\frac{TP}{TP + FP + FN}\\$\\$</span>\n",
    "\n",
    "Where TP is the number of true positives, FP is the number of false\n",
    "positives, and FN is the number of false negatives.\n",
    "\n",
    "Really all this boils down to is looking at how close our predicted\n",
    "labels, if we made every background cluster pixel black, and every\n",
    "foreground cluster pixel 1, is to our ground-truth mask\n",
    "\n",
    "In order to actually assess how well your models did, you of course need\n",
    "something to compare against, so the police manually annotated 4 letters\n",
    "and created masks for them\n",
    "\n",
    "### Task 05-1: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iQqxBfvSGrO8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------\n",
    "# Task 6: Segmentation Metrics\n",
    "# -------------------------------------\n",
    "def calculate_segmentation_metrics(pred, truth, invert=False, visualize=False):\n",
    "    \"\"\"\n",
    "    Calculate Intersection over Union (IoU) to measure segmentation accuracy\n",
    "\n",
    "    Args:\n",
    "        pred: Binary prediction mask (595, 420)\n",
    "        truth: Binary ground truth mask (595, 420)\n",
    "\n",
    "    Returns:\n",
    "        iou: Intersection over Union (IoU) metric\n",
    "    \"\"\"\n",
    "    if visualize:\n",
    "      # Visualize the masks\n",
    "      plt.figure(figsize=(10, 5))\n",
    "      \n",
    "      plt.subplot(1, 2, 1)\n",
    "      plt.title('Prediction Mask')\n",
    "      plt.imshow(pred, cmap='gray')\n",
    "      plt.axis('off')\n",
    "      \n",
    "      plt.subplot(1, 2, 2)\n",
    "      plt.title('Ground Truth Mask')\n",
    "      plt.imshow(truth, cmap='gray')\n",
    "      plt.axis('off')\n",
    "      \n",
    "      plt.show()\n",
    "\n",
    "\n",
    "    # TODO: Convert pred to boolean mask\n",
    "\n",
    "\n",
    "    # TODO: If invert is true, then flip foreground and background labels\n",
    "    if invert:\n",
    "      pass\n",
    "\n",
    "    # TODO: Convert truth to boolean mask\n",
    "\n",
    "\n",
    "    # TODO: Calculate intersection and union\n",
    "\n",
    "\n",
    "    # TODO: calculate IoU (Intersection over Union)\n",
    "    #    hint: this is also known as the Jaccard index\n",
    "    iou = ...\n",
    "    print('IoU:', iou)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsupervised-segmentation",
   "metadata": {},
   "source": [
    "### Task05-2: Description\n",
    "#### Evaluation of Clustering Methods\n",
    "\n",
    "We should probably explore how well each of our unsupervised\n",
    "segmentation methods worked, with different numbers of PCA components.\n",
    "\n",
    "### Task05-2: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfDzIAU2GrO9",
   "metadata": {
    "outputid": "7e63ccff-92db-44a1-d14a-ca1889251465"
   },
   "outputs": [],
   "source": [
    "print(\"\\nPerforming Unsupervised Segmentation...\")\n",
    "for pca_components in [None, 1, 2]:\n",
    "    # TODO: Run Kmeans segmentation, evaluate how well it did\n",
    "    print(f\"Running KMeans with PCA components: {pca_components}\")\n",
    "    segmented_image_kmeans = ...\n",
    "\n",
    "\n",
    "    # TODO Run GMM, evaluate how well it did\n",
    "    print(f\"Running Gaussian Mixture Model with PCA components: {pca_components}\")\n",
    "    segmented_image_gmm = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-output",
   "metadata": {},
   "source": [
    "### Task05-2: Expected Output\n",
    "\n",
    "    Performing Unsupervised Segmentation...\n",
    "    Running KMeans with PCA components: None\n",
    "    IoU: 0.8150511446663399\n",
    "    Running Gaussian Mixture Model with PCA components: None\n",
    "    IoU: 0.8456018086408212\n",
    "    Running KMeans with PCA components: 1\n",
    "    IoU: 0.7816316084529681\n",
    "    Running Gaussian Mixture Model with PCA components: 1\n",
    "    IoU: 0.8448758633563543\n",
    "    Running KMeans with PCA components: 2\n",
    "    IoU: 0.7847515051063914\n",
    "    Running Gaussian Mixture Model with PCA components: 2\n",
    "    IoU: 0.8456018086408212\n",
    "\n",
    "*As we talked about in class, kmeans can be non-deterministic so please\n",
    "don't fret if your numbers are a little different*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supervised-segmentation",
   "metadata": {},
   "source": [
    "### *Story Progression*\n",
    "\n",
    "The unsupervised segmentation seems to work pretty well, but you wonder\n",
    "if a supervised method might work even better. We could probably set\n",
    "this up in a similar way to the clustering task, but instead of using\n",
    "two clusters (foreground and background), we can have two classes\n",
    "(foreground and background).\n",
    "\n",
    "Luckily the police have manually created a binary mask for us that we\n",
    "can use as labelled data to train our supervised model.\n",
    "\n",
    "Unluckily, we need to somehow let each pixel know about the surrounding\n",
    "pixels. So we'll need to somehow create a feature vector for each pixel\n",
    "that contains information about the pixel and the surrounding pixels.\n",
    "\n",
    "Maybe we can take a patch around each pixel and use the RGB values of\n",
    "the pixels in the patch as features?\n",
    "\n",
    "## Task06: Supervised Image Segmentation\n",
    "### Task06-1: Description\n",
    "#### Feature Creation\n",
    "\n",
    "*More Here*\n",
    "\n",
    "### Task06-1: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xqH-pU1mGrO8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------\n",
    "# Task 4: Write Extract Features Function\n",
    "# -------------------------------------\n",
    "def extract_features(image, patch_size=5):\n",
    "    \"\"\"\n",
    "    Extract features for each pixel using RGB values and local neighborhood.\n",
    "\n",
    "    Args:\n",
    "        image: RGB image (595, 420, 3)\n",
    "        patch_size: Size of the local neighborhood patch (must be odd)\n",
    "\n",
    "    Returns:\n",
    "        features: Array of shape (n_pixels, n_features) (249900, 78) (595 x 420, 5 x 5 x 3 + 1 x 3)\n",
    "    \"\"\"\n",
    "    height, width = ...\n",
    "\n",
    "    # TODO: Add padding to image\n",
    "    padding = ...\n",
    "\n",
    "    padded = cv2.copyMakeBorder(\n",
    "        image,\n",
    "        padding, padding, padding, padding,\n",
    "        cv2.BORDER_REFLECT\n",
    "    )\n",
    "\n",
    "\n",
    "    # TODO: Calculate total number of pixels\n",
    "    n_pixels = ...\n",
    "\n",
    "    # TODO: Calculate total number of features per pixel\n",
    "    n_features = ...\n",
    "\n",
    "    # TODO: Initialize data structue to store features for all pixels\n",
    "    features = ...\n",
    "\n",
    "    # TODO: Loop through pixels and extracts features for each pixel\n",
    "    #     hint: the feature vector will be all RGB values for every surrounding pixel concatenated with the pixel itself\n",
    "    #     hint: this results in a 78 dimensional feature vector, for each pixel!\n",
    "    #     hint: 5 x 5 path = 25, 3 colors per pixel gives 3 x 25 = 75 + 3 for the pixel itself again gives 78\n",
    "    #     hint: use current pixel RGB values and the surrounding local patch\n",
    "\n",
    "\n",
    "    # Return feature matrix \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5e90f8",
   "metadata": {},
   "source": [
    "### Task 06-2: Description\n",
    "#### Supervised Image Segmentation via SVM\n",
    "\n",
    "*Instructions*\n",
    "\n",
    "### Task 06-2: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I3oaFW1YGrO8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------\n",
    "# Task 5: SVM Segmentation\n",
    "# -------------------------------------\n",
    "def svm_segmentation(train_image, train_mask, test_image, kernel='rbf', pca_components=10):\n",
    "    # TODO: Extract features of training image\n",
    "    X = ...\n",
    "    y = (train_mask > 0).reshape(-1)\n",
    "\n",
    "    # TODO: Scale features\n",
    "\n",
    "\n",
    "    # TODO: Apply PCA\n",
    "\n",
    "\n",
    "    # TODO: Train SVM\n",
    "\n",
    "\n",
    "    # TODO: Extract features of testing image\n",
    "\n",
    "\n",
    "    # TODO: Apply transformations to testing image\n",
    "    #     hint: transformations means scaling and dimensionality reduction\n",
    "\n",
    "\n",
    "    # TODO: Predict on test image\n",
    "\n",
    "\n",
    "    # Reshape predictions to match image matrix shape\n",
    "    segmented_image = predictions.reshape(test_image.shape[:2])\n",
    "\n",
    "    return segmented_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supervised-segmentation",
   "metadata": {},
   "source": [
    "### Task 06-3: Description\n",
    "#### SVM Segmentation Evaluation\n",
    "\n",
    "Now we can try our supervised segmentation method (SVM) with different\n",
    "kernels and different numbers of PCA components.\n",
    "\n",
    "*This will take a while to run, so be patient!*\n",
    "\n",
    "I encourage you to try different amounts for PCA to see if you can beat\n",
    "my results, but the three I tested were 1, 5, and 10\n",
    "\n",
    "### Task 06-3: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "M0vR5UhmGrO9",
   "metadata": {
    "outputid": "09616445-c296-47c8-eb93-0e33f1abed79"
   },
   "outputs": [],
   "source": [
    "print(\"\\nPerforming Supervised Segmentation...\")\n",
    "for kernel in ['linear', 'poly', 'rbf']:       # Conceptual question: what do 'linear', 'poly' and 'rbf' stand for? Why are we trying each of them as our kernel variable?\n",
    "    for pca_components in [1, 5, 10]:\n",
    "        # TODO: SVM segmentation and evaluation\n",
    "        print(f\"Running SVM with kernel: {kernel} and PCA components: {pca_components}\")\n",
    "        segmented_image_svm = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-output",
   "metadata": {},
   "source": [
    "### Task 06-3: Expected Output\n",
    "\n",
    "    Performing Supervised Segmentation...\n",
    "    Running SVM with kernel: linear and PCA components: 1\n",
    "    IoU: 0.7939733382706887\n",
    "    Running SVM with kernel: linear and PCA components: 5\n",
    "    IoU: 0.7906213147732772\n",
    "    Running SVM with kernel: linear and PCA components: 10\n",
    "    IoU: 0.8016820011500843\n",
    "    Running SVM with kernel: poly and PCA components: 1\n",
    "    IoU: 0.7570233911041068\n",
    "    Running SVM with kernel: poly and PCA components: 5\n",
    "    IoU: 0.8301359011807786\n",
    "    Running SVM with kernel: poly and PCA components: 10\n",
    "    IoU: 0.8775227199564151\n",
    "    Running SVM with kernel: rbf and PCA components: 1\n",
    "    IoU: 0.813663710080135\n",
    "    Running SVM with kernel: rbf and PCA components: 5\n",
    "    IoU: 0.914427174421753\n",
    "    Running SVM with kernel: rbf and PCA components: 10\n",
    "    IoU: 0.9516093009405142"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "region-extraction",
   "metadata": {},
   "source": [
    "## Task 07: Final Letter Region Extraction\n",
    "### Task 07-1: Description\n",
    "#### Region detection and localization function\n",
    "\n",
    "This computer vision stuff is outside the scope of this course, so the\n",
    "code is just provided for you. But this is how we can extract the region\n",
    "of each letter using our segmentation!\n",
    "\n",
    "### Task 07-1: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JXJHmdgqGrO-",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label, regionprops\n",
    "import os\n",
    "\n",
    "def extract_and_save_letters(segmented_image, original_image, output_dir='letters'):\n",
    "    \"\"\"\n",
    "    Extract each segmented letter and save as a separate PNG file.\n",
    "    \n",
    "    Args:\n",
    "        segmented_image: Segmented image with unique labels for each letter\n",
    "        original_image: Original RGB image\n",
    "        output_dir: Directory to save the extracted letter images\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Label connected components\n",
    "    labeled_image = label(segmented_image)\n",
    "    \n",
    "    # Iterate over each labeled region\n",
    "    for region in regionprops(labeled_image):\n",
    "        # Extract the bounding box of the region\n",
    "        min_row, min_col, max_row, max_col = region.bbox\n",
    "        \n",
    "        # Extract the region from the original image\n",
    "        letter_image = original_image[min_row:max_row, min_col:max_col]\n",
    "        \n",
    "        # Save the extracted letter as a PNG file\n",
    "        letter_filename = os.path.join(output_dir, f'letter_{region.label}.png')\n",
    "        cv2.imwrite(letter_filename, cv2.cvtColor(letter_image, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapping-up",
   "metadata": {},
   "source": [
    "### Task 07-2: Description\n",
    "#### Letter extraction\n",
    "\n",
    "Lets actually use our best combination to extract each letter as a png!\n",
    "\n",
    "### Task 07-2: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Au56gvNRqJUl",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_image = svm_segmentation(train_image, train_mask, test_image, kernel='rbf', pca_components=10)\n",
    "extract_and_save_letters(segmented_image, test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "up-next",
   "metadata": {},
   "source": [
    "### *Story Progression*\n",
    "\n",
    "Now that we have all of the letters extracted, we can perform Optical\n",
    "Character Recognition (OCR) on each letter to extract the text. The next\n",
    "homework we'll explore how to do this with a basic Feed-Forward Neural\n",
    "Network (which you'll be writing from scratch) and a Convolutional\n",
    "Neural Network (which you'll be using from PyTorch)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
