{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Practicum: Heart Disease Dataset\n",
    "\n",
    "In this practicum, we will explore the Heart Disease dataset using unsupervised learning methods and then apply several supervised learning algorithms. \n",
    "\n",
    "This Practicum covers the following topics:\n",
    "\n",
    "* Principle Component Analysis\n",
    "* t-SNE\n",
    "* KMeans Clustering\n",
    "* Evaluation of ML Models\n",
    "* Ensemble Learning\n",
    "* [BONUS] Neural Networks\n",
    "\n",
    "It will consist of 5 tasks:\n",
    "\n",
    "| Task ID  | Description                                      | Points |\n",
    "|----------|--------------------------------------------------|--------|\n",
    "| 00       | Load and Prepare Dataset                                     |       |\n",
    "| 01       | Visualizations                              |       |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;01-1     | &nbsp;&nbsp;&nbsp;&nbsp;-  Standardize the dataset                  |       |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;01-2     | &nbsp;&nbsp;&nbsp;&nbsp;-  Visualize with PCA                  |       |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;01-3     | &nbsp;&nbsp;&nbsp;&nbsp;-  Visualize with t-SNE                  |       |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;01-4     | &nbsp;&nbsp;&nbsp;&nbsp;-  Cluster with KMeans                  |       |\n",
    "| 02       | Evaluating Supervised Classifiers                 |       |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;02-1     | &nbsp;&nbsp;&nbsp;&nbsp;-  Create SVM and Param grid                  |       |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;02-2     | &nbsp;&nbsp;&nbsp;&nbsp;-  Perform grid search                  |       |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;02-3     | &nbsp;&nbsp;&nbsp;&nbsp;-  Calculate Evaluation metrics                  |       |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;02-4     | &nbsp;&nbsp;&nbsp;&nbsp;-  Visualize with Confusion Matrix                  |       |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;02-5     | &nbsp;&nbsp;&nbsp;&nbsp;-  Synthetically Balance Dataset                  |       |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;02-6     | &nbsp;&nbsp;&nbsp;&nbsp;-  Compare Classifiers on Balanced and Unbalanced Dataset                  |       |\n",
    "| 03       | Ensemble Learning                     |        |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;03-1     | &nbsp;&nbsp;&nbsp;&nbsp;-  Simple voting ensemble                  |       |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;03-2     | &nbsp;&nbsp;&nbsp;&nbsp;- Stacking ensemble                  |       |\n",
    "| 04       | [BONUS] Simple Neural Network                     |        |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;04-1     | &nbsp;&nbsp;&nbsp;&nbsp;- Network Architecture                  |       |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;04-2     | &nbsp;&nbsp;&nbsp;&nbsp;- Network Parameters                  |       |\n",
    "| &nbsp;&nbsp;&nbsp;&nbsp;04-3     | &nbsp;&nbsp;&nbsp;&nbsp;- Test Network on Balanced and Unbalanced Data                  |       |\n",
    "\n",
    "### *Story Progression*\n",
    "Per Dogtor Golden, we need to make sure that we get at least an 80% accuracy on the dataset so we can save more pets at the pet hospital!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 00: Load and Prepare Data\n",
    "### Task 00: Description\n",
    "#### Load data\n",
    "\n",
    "For this task, we need to load in the dataset and fix any missing values. The Heart Disease dataset contains 303 samples with 14 features. The task is to classify the risk level a patient has for heart disease with a class label of 0-4. Let's load it in and take a quick look at the structure of the dataset.\n",
    "\n",
    "### Task 00: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "np.seterr(divide='ignore', over='ignore', invalid='ignore')\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    REPO_URL = \"https://github.com/nd-cse-30124-fa25/cse-30124-homeworks.git\"\n",
    "    REPO_NAME = \"cse-30124-homeworks\"\n",
    "    HW_FOLDER = \"practicum\" \n",
    "\n",
    "    # Clone repo if not already present\n",
    "    if not os.path.exists(REPO_NAME):\n",
    "        !git clone {REPO_URL}\n",
    "\n",
    "    # cd into the homework folder\n",
    "    %cd {REPO_NAME}/{HW_FOLDER}\n",
    "\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data'\n",
    "col_names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
    "# Load Heart Disease dataset\n",
    "# df = pd.read_csv(url, names=col_names, na_values='?')\n",
    "df = pd.read_csv('./heart.csv', names=col_names, na_values='?')\n",
    "df.head()\n",
    "\n",
    "# Assuming df is your DataFrame and 'target' is your target column\n",
    "# Number of samples\n",
    "num_samples = df.shape[0]\n",
    "\n",
    "# Number of features (excluding the target column)\n",
    "num_features = df.shape[1] - 1  # Subtract 1 for the target column\n",
    "\n",
    "# Number of unique target values\n",
    "num_unique_targets = df['target'].nunique()\n",
    "\n",
    "# Unique target values and their counts\n",
    "unique_target_values = df['target'].value_counts()\n",
    "\n",
    "print(f\"Number of samples: {num_samples}\")\n",
    "print(f\"Number of features: {num_features}\")\n",
    "print(f\"Number of unique target values: {num_unique_targets}\")\n",
    "print(\"\\nUnique target values and their counts:\")\n",
    "print(unique_target_values)\n",
    "\n",
    "# Check for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "# Fill missing values with the median for simplicity\n",
    "df.fillna(df.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 01: Visualizations\n",
    "### Task 01-1: Description\n",
    "#### Standardize Data\n",
    "\n",
    "To visualize our data we'll probably need to reduce its dimensionality, since it has 13 features out of the box. One method for doing that we know of is Principal Component Analysis!\n",
    "The first thing we'll need to do is standardize the data.\n",
    "\n",
    "### Task 01-1: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# TODO: Scale the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 01-2: Description\n",
    "#### Visualize Data with PCA\n",
    "\n",
    "Now that our data is standardized we can run PCA on it to reduce it to two dimensions and then display the data using `pyplot`\n",
    "\n",
    "### Task 01-2: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# TODO: Use PCA to reduce to 2D for visualization\n",
    "\n",
    "# Plot PCA result\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1])\n",
    "plt.title('PCA of Heart Disease Dataset')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 01-3: Description\n",
    "#### Visualize Data with t-SNE\n",
    "\n",
    "Unfortunately PCA doesn't do anything to make sure our data points maintain their local structure, so it's actually not the best option for visualizing high dimensional data. A better option is using a technique called t-SNE, which better preserves the local relationships between points.\n",
    "\n",
    "### Task 01-3: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TODO: Apply t-SNE to the scaled dataset\n",
    "\n",
    "# Plot the t-SNE result\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1])\n",
    "plt.colorbar(label='Target')\n",
    "plt.title('t-SNE Visualization of Heart Disease Dataset')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well things are certainly more spread out than in PCA but I don't really see any clear clusters. However we can try clustering with K-Means and see if we can find any, no need to just guess visually!\n",
    "\n",
    "### Task 01-4: Description\n",
    "#### Cluster with kmeans\n",
    "\n",
    "Luckily we know there should be 5 distinct groups in our data somewhere, lets see how KMeans would split our data into 5 different groups and then because we actually have the labels, lets overlay those to try and get a sense of how seperable our data actually is!\n",
    "\n",
    "### Task 01-4: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# TODO: Apply K-Means\n",
    "\n",
    "# Plot K-Means result\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters_kmeans)\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df['target'], marker='x')\n",
    "plt.title('K-Means Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's definitely some clear groupings here, but that's kind of to be expected with kmeans, since it will always force an answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 02: Evaluating Supervised Classifiers\n",
    "### Task 02-1: Description\n",
    "#### Initialize Hyperparameter grid\n",
    "\n",
    "Since we have ground-truth, we can use supervised learning techniques to try and get that `80%` accuracy we need! Lets start with an SVM. We should probably try several different combinations.\n",
    "\n",
    "### Task 02-1: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the SVM model\n",
    "svm = SVC()\n",
    "\n",
    "# TODO: Define the parameter grid to search\n",
    "\n",
    "# TODO: Initialize GridSearchCV with cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 02-2: Description\n",
    "#### Test SVM with grid search\n",
    "\n",
    "Lets try all of our different combinations of parameters we defined above with a grid search to figure out what the best combination is!\n",
    "\n",
    "### Task 02-2: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit the grid search to the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 02-3: Description\n",
    "#### Evaluate results of grid search\n",
    "\n",
    "Lets print out the metrics for our different combinations and try and see what the best set is!\n",
    "\n",
    "### Task 02-3: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract results into a DataFrame\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Select relevant columns and rename 'mean_test_score' to 'accuracy'\n",
    "results = results[['mean_test_score', 'param_kernel', 'param_C', 'param_degree', 'param_gamma']]\n",
    "results.rename(columns={'mean_test_score': 'accuracy'}, inplace=True)\n",
    "\n",
    "# Fill NaN values for non-applicable parameters with 'None' for clarity\n",
    "results.fillna('None', inplace=True)\n",
    "\n",
    "# Reorder columns to make 'accuracy' the first column\n",
    "results = results[['accuracy', 'param_kernel', 'param_C', 'param_degree', 'param_gamma']]\n",
    "\n",
    "# Sort by accuracy\n",
    "results = results.sort_values(by='accuracy', ascending=False)\n",
    "\n",
    "# Print the table with all columns\n",
    "pd.set_option('display.max_columns', None)  # Ensure all columns are displayed\n",
    "print(results)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"\\nBest parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation accuracy: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "# Use the best estimator to make predictions\n",
    "best_svm = grid_search.best_estimator_\n",
    "y_pred_best_svm = best_svm.predict(X_test)\n",
    "\n",
    "# TODO: Display classification report for the best SVM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 02-4: Description\n",
    "#### Visualize Classification Results with Confusion Matrix\n",
    "\n",
    "Lets use a confusion matrix to see what kind of errors our classifier is making.\n",
    "\n",
    "### Task 02-4: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Confusion matrix for the best SVM model\n",
    "\n",
    "sns.heatmap(cm_best_svm, annot=True, fmt='d')\n",
    "plt.title('Best SVM Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 02-5: Description\n",
    "#### Balance Dataset\n",
    "\n",
    "The confusion matrix makes it clear that our dataset is really imbalanced and this probably effects the accuracy of our classifier. Luckily we can use a special technique to help balance our dataset\n",
    "\n",
    "### Task 02-5: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# EDA: Check class distribution\n",
    "sns.countplot(x='target', data=df)\n",
    "plt.title('Class Distribution')\n",
    "plt.show()\n",
    "\n",
    "X = df.drop(columns='target')\n",
    "y = df['target']\n",
    "\n",
    "# TODO: Standardize features\n",
    "\n",
    "# TODO: Apply SMOTE\n",
    "\n",
    "# Check new class distribution\n",
    "sns.countplot(x=y_resampled)\n",
    "plt.title('Class Distribution After SMOTE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 02-6: Description\n",
    "#### Balance Dataset\n",
    "\n",
    "Now that we have a balanced dataset, lets see what difference it made for a collection of different supervised classifiers! In addition to the RBF SVM, lets try Logistic Regression, KNN, Decision Trees, and Naive Bayes.\n",
    "\n",
    "### Task 02-6: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Define a function to evaluate different models with additional strategies\n",
    "def evaluate_models(X, y):\n",
    "    # TODO: List of models to evaluate\n",
    "    \n",
    "    # TODO: Feature selection\n",
    "\n",
    "    # TODO: Dimensionality reduction\n",
    "\n",
    "    # TODO: Evaluate each model\n",
    "    for name, model in models.items():\n",
    "        \n",
    "        # TODO: Perform cross-validation\n",
    "        \n",
    "        print(f\"{name} Accuracy: {scores.mean():.2f} (+/- {scores.std() * 2:.2f})\")\n",
    "\n",
    "# Evaluate models on the scaled dataset\n",
    "print('Imbalanced Results:')\n",
    "evaluate_models(X_scaled, df['target'])\n",
    "\n",
    "print('-'*80)\n",
    "\n",
    "# Evaluate models on the resampled dataset\n",
    "print('Balanced Results:')\n",
    "evaluate_models(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## TODO: Ensemble Classifiers\n",
    "\n",
    "We could use an ensemble of classifiers!\n",
    "\n",
    "Let's try an ensemble of Logistic Regression, Random Forest, and Gradient Boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Story Progression*\n",
    "While balancing the classes didn't help every method equally, it greatly improved the SVM's and KNN's performance.\n",
    "\n",
    "Unfortunately though, none of these classifiers were able to get to the 80% accuracy that the Dogtors wanted and so maybe we can't save any pets after all :(\n",
    "\n",
    "## Task 03: Ensemble Learning\n",
    "### Task 03-1: Description\n",
    "#### Simple Voting Ensemble Classifier \n",
    "\n",
    "Lets try and combine several ML classifiers to see if we can improve our results!\n",
    "\n",
    "### Task 03-1: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Define a function to evaluate different models with additional strategies\n",
    "def evaluate_models(X, y):    \n",
    "    # TODO: Feature selection\n",
    "\n",
    "    # TODO: Dimensionality reduction\n",
    "\n",
    "    # TODO: Ensemble method: Voting Classifier\n",
    "    \n",
    "    # TODO: Create a pipeline for the ensemble\n",
    "\n",
    "    # TODO: Perform cross-validation for the ensemble\n",
    "\n",
    "    print(f\"Ensemble (Voting) Accuracy: {ensemble_scores.mean():.2f} (+/- {ensemble_scores.std() * 2:.2f})\")\n",
    "\n",
    "# Evaluate models on the scaled dataset\n",
    "print('Imbalanced Results:')\n",
    "evaluate_models(X_scaled, df['target'])\n",
    "\n",
    "print('-'*80)\n",
    "\n",
    "# Evaluate models on the resampled dataset\n",
    "print('Balanced Results:')\n",
    "evaluate_models(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Task 03-2: Description\n",
    "#### Stacking Ensemble Classifier \n",
    "\n",
    "We tried voting, but lets try a stacking classifier too\n",
    "\n",
    "### Task 03-2: Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Define a function to evaluate different models with additional strategies\n",
    "def evaluate_models(X, y):    \n",
    "    # TODO: Feature selection\n",
    "\n",
    "    # TODO: Dimensionality reduction\n",
    "\n",
    "    # TODO: Ensemble method: Voting Classifier\n",
    "    \n",
    "    # TODO: Create a pipeline for the ensemble\n",
    "\n",
    "    # TODO: Perform cross-validation for the ensemble\n",
    "\n",
    "    print(f\"Ensemble (Voting) Accuracy: {ensemble_scores.mean():.2f} (+/- {ensemble_scores.std() * 2:.2f})\")\n",
    "\n",
    "# Evaluate models on the scaled dataset\n",
    "print('Imbalanced Results:')\n",
    "evaluate_models(X_scaled, df['target'])\n",
    "\n",
    "print('-'*80)\n",
    "\n",
    "# Evaluate models on the resampled dataset\n",
    "print('Balanced Results:')\n",
    "evaluate_models(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Story Progression*\n",
    "#### OH MY GOODNESS WE DID IT\n",
    "Would you look at that, we were able to get above 80% accuracy by simply combining different basic ML models together!\n",
    "\n",
    "But wait, the Dogtors said that given the current state of the market they'd really love to use AI (obviously this ML stuff isn't *real* AI) to solve this problem so they can bring in more funding. It turns out there's another technique we could use!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 04: Simple Neural Network\n",
    "### Task 04: Description\n",
    "#### Simple FFN\n",
    "\n",
    "Lets see if we can create a basic neural network to help the dogtors get extra funding while still saving the pets!\n",
    "\n",
    "### Task 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def make_loader(X, y, batch_size=32, shuffle=False):\n",
    "    X_t = torch.tensor(X, dtype=torch.float32)\n",
    "    y_t = torch.tensor(y.values, dtype=torch.long)\n",
    "    return DataLoader(TensorDataset(X_t, y_t), batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "X_train_u, X_test_u, y_train_u, y_test_u = train_test_split(\n",
    "    X_scaled, df['target'], test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "train_loader_u = make_loader(X_train, y_train, shuffle=True)\n",
    "test_loader_u  = make_loader(X_test, y_test)\n",
    "\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "train_loader_b = make_loader(X_train, y_train, shuffle=True)\n",
    "test_loader_b  = make_loader(X_test, y_test)\n",
    "\n",
    "# TODO: Define a simple neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 128\n",
    "num_classes = len(df['target'].unique())\n",
    "\n",
    "# TODO: Initialize model, criterion, optimizer, and epochs\n",
    "\n",
    "def train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, epochs=100):\n",
    "    results = []\n",
    "    for run in range(10):\n",
    "        # Training loop\n",
    "        num_epochs = epochs\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                # Forward pass\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                \n",
    "                # Backward pass and optimization\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Evaluate the model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                outputs = model(X_batch)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += y_batch.size(0)\n",
    "                correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "            print(f'Accuracy of the model on the test set: {100 * correct / total:.2f}%')\n",
    "            results.append(100 * correct / total)\n",
    "\n",
    "    print(f'Average accuracy over {len(results)} runs: {np.mean(results):.2f}%')\n",
    "\n",
    "print(\"Unbalanced Dataset Results:\")\n",
    "train_and_evaluate(model, train_loader_u, test_loader_u, criterion, optimizer)\n",
    "\n",
    "print('-'*80)\n",
    "\n",
    "print(\"Balanced Dataset Results:\")\n",
    "train_and_evaluate(model, train_loader_b, test_loader_b, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap-Up\n",
    "In this practicum, we applied both unsupervised (PCA and clustering) and supervised (Random Forest) methods to the Heart Disease dataset. By first exploring the data using unsupervised techniques, we were able to gain insights that informed our supervised task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
